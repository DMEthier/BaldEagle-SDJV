---
title: "DataManip"
author: "Danielle Ethier"
date: '2022-07-06'
output: html_document
editor_options: 
  chunk_output_type: console
---
Example found here: 
https://htmlpreview.github.io/?https://github.com/eco4cast/Statistical-Methods-Seminar-Series/blob/main/Rota-MSOM/MSOM-Presentation.html

Test multi-species occupancy model with the BCCWS data set first. 

#Load libraries

```{r libraries}

#You can install naturecounts from GitHub with the remotes package if you don't have it already. 
#install.packages("remotes")
#remotes::install_github("BirdsCanada/naturecounts")

require(naturecounts)
require(tidyverse)
require(unmarked)
require(lubridate)
require(reshape)
require(reshape2)
require(nloptr)
require(ggpubr)

out.dir <- paste("Output/")
```

#Download data from NatureCounts

```{r download dat}

#BCCWS<-nc_data_dl(collection="BCCWS", username = "dethier", info="BAEA analysis", fields_set = "extended")

#write.csv(BCCWS, "BCCWS_11Aug2022.csv")

BCCWS<-read.csv("BCCWS_11Aug2022.csv")

```

#BCCWS Data cleaning

```{r clean}

#retain desired data columns
dat<-BCCWS %>% select(SpeciesCode, survey_year, survey_month, survey_day, SiteCode, SamplingEventIdentifier, SurveyAreaIdentifier, latitude, longitude, DurationInHours, TimeCollected, CollectorNumber, DurationInHours, EffortUnits2, EffortMeasurement2, ObservationCount, ObservationCount2, ObservationCount3, ObservationCount4)

dat <- dat %>% mutate(date = ymd(paste(survey_year, survey_month, survey_day, sep = "/")), doy = yday(date))

#drop site with missing lat and long
dat<-dat %>% filter(latitude != "NA")

#assign winter period
dat<-dat %>% mutate(period=ifelse(survey_month %in%c(9, 10, 11, 12), survey_year+1, survey_year))

# parse out form ID number and delete bad forms
dat$form.id <- gsub("BCCWS-", "", dat$SamplingEventIdentifier)
dat <- subset(dat, form.id != 3794 & form.id != 5469 &
	form.id != 5063 & form.id != 6945) %>% select(-form.id)

#filter bad dates
dat <- dat %>% filter(!(SurveyAreaIdentifier == "LMSQ-3" & SpeciesCode == "BAEA" & survey_year == "1999" & survey_month == "12" & survey_day == "12"))

#remove sites outside the Salish Sea using auxiliary table
dat$area.reg <- substring(dat$SurveyAreaIdentifier, 1,4)
# the following drops sites not classified as the Salish Sea. Updated April 2020
SS.sites <- read.csv("bccws.salishsea.csv")
dat <- merge(dat, SS.sites, by = "area.reg")

#Detection Covariates

#create new visibility metric, assign NA the mean value (885)
dat<-dat %>% mutate(visibility=ifelse(EffortMeasurement2=="750m", 750, ifelse(EffortMeasurement2=="500m", 500, ifelse(EffortMeasurement2=="1 km", 1000, ifelse(EffortMeasurement2=="100m", 100, ifelse(EffortMeasurement2=="250m", 250, ifelse(EffortMeasurement2=="<100m", 50, ifelse(EffortMeasurement2=="Unlimited", 1500, 885)))))))) %>% select(-EffortUnits2, -EffortMeasurement2) 

dat<-dat %>% mutate(vis=replace_na(visibility, 885)) %>% select(-visibility)

#create a new duration metric, assign NA the mean value (1.7)
dat<-dat %>% mutate(duration=replace_na(DurationInHours, 1.7)) %>% select(-DurationInHours)

#create a new time of day metric, and assign the NA the mean value (11.11)
dat<-dat %>% mutate(tod=replace_na(TimeCollected, 11.11)) %>% select(-TimeCollected)

```

#BCCWS Events Matrix 
Need this to properly zero-fill the data matrix

```{r events}

events<-dat %>% select(SiteCode, period, survey_year, survey_month, survey_day, tod, duration, vis, latitude, longitude) %>% distinct()

events<-events %>% mutate(date = ymd(paste(period, survey_month, survey_day, sep = "/")), doy = yday(date))

```

#Limit samples in events matrix

Also, similar to de Zwann, we will want to limit the Only routes that were visited during all four months (12,1,2,3) for at least 3 years within the 20-year study period will be retained. 

###Update needed###
***Limit to cover the same temporal period as the PSSS (2009-2022)***

```{r month}

#Limit the survey to one per month (sometime extras are run).
events<-events %>% group_by(SiteCode, period, survey_month) %>% slice_max(survey_day) 

events<-events %>% distinct(SiteCode, period, doy, .keep_all = TRUE)

events<-as.data.frame(events)

#filter for desired months
events<-events %>% filter(survey_month %in% c(12,1,2,3))

#filter to cover that same years as PSSS (2009-2022)
events<-events %>% filter(period>=2009)

#site must be visit all 4 times
test<-events %>% group_by(SiteCode, period) %>% summarise(visits=length(survey_month)) %>% filter(visits>=4) %>% select(-visits)

events<-inner_join(events, test, by=c("SiteCode", "period"))

#site must be visited for 3 years
test2<-events %>% group_by(SiteCode) %>% summarise(yrs=n_distinct(period)) %>% filter(yrs>=3) %>% select(-yrs)

events<-inner_join(events, test2, by=c("SiteCode"))

#write.csv(events, "EventsBCCWS.csv")
#events<-read.csv("EventsBCCWS.csv")

```

#Detection Matrix
Create the species detection/no detection matrix for target species

Target Species
"BAEA"
"SUSC"
"WWSC"
"BLSC"
"LTDU"

```{r detect}

sp.list<-c("BAEA", "SUSC", "WWSC", "BLSC", "LTDU")

#create sp loop

for(m in 1:length(sp.list)) {
  
 # m<-1 #for testing
  
  sp.dat<-dat %>% filter(SpeciesCode==sp.list[m])
  
  sp.dat<-sp.dat %>% select(period, survey_month, survey_day, SiteCode, ObservationCount)
  
#define the core winter months as Dec-March 
  
  sp.dat<-sp.dat %>% filter(survey_month %in% c(12,1,2,3))
  sp.dat<-sp.dat %>% filter(period>=2009)
  events1<-events %>% select(-latitude, -longitude)
  
#zero-fill the dataframe
  
  sp.dat<-left_join(events1, sp.dat, by=c("period", "survey_month", "survey_day", "SiteCode"))
  
  sp.dat<-sp.dat %>% distinct(period, survey_month, survey_day, SiteCode, .keep_all = TRUE)
  
sp.dat<-sp.dat %>% mutate(detection=ifelse(ObservationCount>=1, 1, 0))  %>% replace_na(list(detection=0)) %>% mutate(Site=paste(SiteCode, period, sep="-")) %>% select(-ObservationCount, -SiteCode, -period, -survey_day) %>% arrange(Site) 

#recast the data.frame  
  sp<-cast(sp.dat, Site~survey_month, value="detection", fun.aggregate = "max")

#replace Inf in data by NA
 sp <- do.call(data.frame,lapply(sp, function(x) replace(x,is.infinite(x), NA)))
 
 sp<- sp %>% select(X12, X1, X2, X3)
 sp<-as.matrix(sp)
 
 write.csv(sp, paste(sp.list[m], "detectBCCWS.csv", sep=""))
 
} # end sp.loop

```

#Observer-level Detection Covariates

These detection covariates were selected base on modelling outputs from deZwaan's works using the BCCWS (unpublished)

Time of Day = tod
Day of Year = doy
Survey duration = duration
Visibility = vis

```{r detectcov}

cov.dat<-events %>% mutate(Site=paste(SiteCode, period, sep="-"))  %>% select(-SiteCode) %>% arrange(Site)

#Time of Day  
#recast the data.frame  
time<-cast(cov.dat, Site~survey_month, value="tod", fun.aggregate = "max")

#replace Inf in data with the mean value
time <- do.call(data.frame,lapply(time, function(x) replace(x,is.infinite(x), 11.11)))

time<- time %>% select(X12,X1,X2,X3)

#standardize all variables
time<-time %>% mutate_at(c('X12', 'X1', 'X2', 'X3'), ~(scale(.) %>% as.vector))

time<-as.matrix(time)
write.csv(time, "detBCCWS_tod.csv")

#Duration
#recast the data.frame  
dur<-cast(cov.dat, Site~survey_month, value="duration", fun.aggregate = "max")

#replace Inf in data with the mean value
dur <- do.call(data.frame,lapply(dur, function(x) replace(x,is.infinite(x), 1.7)))

dur<- dur %>% select(X12,X1,X2,X3)

#standardize all variables
dur<-dur %>% mutate_at(c('X12', 'X1', 'X2', 'X3'), ~(scale(.) %>% as.vector))

dur<-as.matrix(dur)
write.csv(dur, "detBCCWS_dur.csv")

#Visibility
#recast the data.frame  
vis<-cast(cov.dat, Site~survey_month, value="vis", fun.aggregate = "max")

#replace Inf in data with the mean value
vis <- do.call(data.frame,lapply(vis, function(x) replace(x,is.infinite(x), 885)))

vis<- vis %>% select(X12,X1,X2,X3)

#standardize all variables
vis<-vis %>% mutate_at(c('X12', 'X1', 'X2', 'X3'), ~(scale(.) %>% as.vector))

vis<-as.matrix(vis)
write.csv(vis, "detBCCWS_vis.csv")

#Day of year
#doy needs to start at 1 and sequence upwards. Import data specific file to do this
doy<-read.csv("doy.csv")
doy<-left_join(cov.dat, doy, by="doy")

#recast the data.frame  
doy<-cast(doy, Site~survey_month, value="Day", fun.aggregate = "max")

#replace Inf in data with the mean value
doy<- do.call(data.frame,lapply(doy, function(x) replace(x,is.infinite(x), 57.07)))
doy<- doy %>% select(X12,X1,X2,X3)

#standardize all variables
doy<-doy%>% mutate_at(c('X12', 'X1', 'X2', 'X3'), ~(scale(.) %>% as.vector))

doy<-as.matrix(doy)
write.csv(vis, "detBCCWS_doy.csv")

```

#Site-level Occupancy Covariates

Occupancy covaraites of interest include:
latitude 
longitude
year
collection
region** (still need to assign)

```{r occcov}

occ.dat<-events %>% select(SiteCode, period, doy, latitude, longitude) %>% distinct(period, SiteCode, .keep_all = TRUE)

#retain only those in the events layer
#occ.dat<-left_join(events, occ.dat, by=c("SiteCode", "period", "doy"))

occ.dat<-occ.dat %>% mutate(Site=paste(SiteCode, period, sep="-")) %>% arrange(Site)  %>% distinct(Site, .keep_all = TRUE) #%>% select(-SiteCode)

#standardize year so that the first year of the analysis is 1
min.yr<-min(occ.dat$period)
max.yr<-max(occ.dat$period)

occ.dat<-occ.dat %>% mutate(year_st=(period-min.yr)+1)

#standardize all variables
#need to do this in the next step
#occ.dat<-occ.dat %>% mutate_at(c('latitude', 'longitude'), ~(scale(.) %>% as.vector)) %>% select(Site, year_st, latitude, longitude)

#Assign Collection identifier
occ.dat$collection<-1

write.csv(occ.dat, "obsCovsBCCWS.csv")
  
```

